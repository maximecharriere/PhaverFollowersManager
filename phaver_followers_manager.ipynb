{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "import pandas as pd\n",
    "import os\n",
    "import time\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Constants & Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "PHAVER_GRAPHQL_ENDPOINT = os.getenv(\"PHAVER_GRAPHQL_ENDPOINT\")\n",
    "PHAVER_PROFILE_ID = os.getenv(\"PHAVER_PROFILE_ID\")\n",
    "\n",
    "FIREBASE_TOKEN_URL = os.getenv(\"FIREBASE_API_URL\") + os.getenv(\"FIREBASE_API_KEY\")\n",
    "FIREBASE_REFRESH_TOKEN = os.getenv(\"FIREBASE_REFRESH_TOKEN\")\n",
    "\n",
    "LIMIT_PER_REQUEST = 1000\n",
    "MAX_FOLLOWINGS_REQUESTED = 5000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load GrapgQL Query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utility function to load a GraphQL query or fragment from a file\n",
    "def load_graphql_file(file_path):\n",
    "    with open(file_path, 'r') as file:\n",
    "        return file.read()\n",
    "    \n",
    "# Load fragments and query from their respective files\n",
    "FRAGMENTS = load_graphql_file('graphql/fragments/Fragments.gql')\n",
    "FOLLOWINGS_QUERY = load_graphql_file('graphql/queries/FollowingsQuery.gql')\n",
    "FOLLOWERS_QUERY = load_graphql_file('graphql/queries/FollowersQuery.gql')\n",
    "POINTS_QUERY = load_graphql_file('graphql/queries/PointsQuery.gql')\n",
    "SET_FOLLOW_MUTATION = load_graphql_file('graphql/mutations/SetFollowMutation.gql')\n",
    "PROFILE_QUERY = load_graphql_file('graphql/queries/ProfileQuery.gql')\n",
    "QUOTA_QUERY = load_graphql_file('graphql/queries/QuotaQuery.gql')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def request_access_token():\n",
    "    payload = {\n",
    "        \"grantType\": \"refresh_token\",\n",
    "        \"refreshToken\": FIREBASE_REFRESH_TOKEN\n",
    "    }\n",
    "\n",
    "    response = requests.post(FIREBASE_TOKEN_URL, json=payload)\n",
    "    response.raise_for_status()\n",
    "    access_data = response.json()\n",
    "    return access_data['access_token']\n",
    "\n",
    "def phaver_graphql_api_request(query, variables, access_token):\n",
    "    headers = {\n",
    "        \"Authorization\": \"Bearer \" + access_token,\n",
    "        \"Content-Type\": \"application/json\"\n",
    "    }\n",
    "\n",
    "    payload = {\n",
    "        \"query\": query,\n",
    "        \"variables\": variables\n",
    "    }\n",
    "\n",
    "    response = requests.post(\n",
    "        PHAVER_GRAPHQL_ENDPOINT, \n",
    "        headers=headers, \n",
    "        json=payload\n",
    "    )\n",
    "\n",
    "    # Raise an exception for HTTP errors\n",
    "    if response.status_code != 200:\n",
    "        print(response.headers)\n",
    "        response.raise_for_status()\n",
    "\n",
    "    # Parse the JSON response\n",
    "    data = response.json()\n",
    "\n",
    "    # Check if the response contains any errors\n",
    "    if 'errors' in data:\n",
    "        raise Exception(data['errors'])\n",
    "    \n",
    "    time.sleep(1)\n",
    "    return data\n",
    "\n",
    "def addToClipBoard(text):\n",
    "    command = 'echo ' + text.strip() + '| clip'\n",
    "    os.system(command)\n",
    "\n",
    "def save_to_json(data, filename):\n",
    "    \"\"\"Save the data to a JSON file\"\"\"\n",
    "    # create the folder if it doesn't exist\n",
    "    folder = os.path.dirname(filename)\n",
    "    os.makedirs(folder, exist_ok=True)\n",
    "    with open(filename, 'w') as f:\n",
    "        json.dump(data, f, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Request Token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "access_token = request_access_token()\n",
    "addToClipBoard(\"Bearer \" + access_token)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Followings Manager Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def request_followings(profile_id, limit_per_request, offset, access_token):\n",
    "    \"\"\"Fetch a batch of followings from the API\"\"\"\n",
    "\n",
    "    data = phaver_graphql_api_request(\n",
    "        query = FRAGMENTS + FOLLOWINGS_QUERY, \n",
    "        variables = {\n",
    "            \"profileId\": profile_id,\n",
    "            \"limit\": limit_per_request,\n",
    "            \"offset\": offset\n",
    "        }, \n",
    "        access_token = access_token\n",
    "    )\n",
    "\n",
    "    # get the followings from the response\n",
    "    followings = data['data']['followings']\n",
    "    \n",
    "    return followings\n",
    "\n",
    "def request_points(profile_id, access_token):\n",
    "    \"\"\"Fetch the points for a profile from the API\"\"\"\n",
    "\n",
    "    data = phaver_graphql_api_request(\n",
    "        query = FRAGMENTS + POINTS_QUERY, \n",
    "        variables = {\n",
    "            \"profileId\": profile_id\n",
    "        }, \n",
    "        access_token = access_token\n",
    "    )\n",
    "   \n",
    "    # get the points from the response\n",
    "    points = data['data']['phaverPoints']['phaverPointsCurrent']\n",
    "    \n",
    "    return points\n",
    "\n",
    "def get_all_points(followings, access_token):\n",
    "    \"\"\"Fetch all points by iterating over paginated results\"\"\"\n",
    "    for following in followings:\n",
    "        profile_id = following['followedProfile']['id']\n",
    "        points = request_points(profile_id, access_token)\n",
    "        following['followedProfile']['points'] = points\n",
    "    return followings\n",
    "\n",
    "\n",
    "def get_all_followings(profile_id, limit_per_request, max_followings_requested, access_token):\n",
    "    \"\"\"Fetch all followings by iterating over paginated results\"\"\"\n",
    "    all_followings = []\n",
    "    offset = 0\n",
    "    \n",
    "    while len(all_followings) < max_followings_requested:\n",
    "        followings = request_followings(profile_id, limit_per_request, offset, access_token)\n",
    "        \n",
    "        # If no more followings, break the loop\n",
    "        if not followings:\n",
    "            break\n",
    "        \n",
    "        # Append the fetched followings to the list\n",
    "        all_followings.extend(followings)\n",
    "        \n",
    "        # Increment the offset by the limit for pagination\n",
    "        offset += limit_per_request\n",
    "        \n",
    "    return all_followings\n",
    "\n",
    "# Function to flatten the JSON data\n",
    "def flatten_followings(followings):\n",
    "    \"\"\"Flatten the followings JSON data into Pandas DataFrame\"\"\"\n",
    "\n",
    "    flattened_data = []\n",
    "\n",
    "    for item in followings:\n",
    "        followed_profile = item['followedProfile']\n",
    "       \n",
    "        # Flatten the nested fields\n",
    "        flattened_profile = {\n",
    "            \"id\": followed_profile.get(\"id\"),\n",
    "            \"username\": followed_profile.get(\"username\"),\n",
    "            \"profileCreatedAt\": followed_profile.get(\"createdAt\"),\n",
    "            \"followingDate\": item.get(\"createdAt\"),\n",
    "            \"followerCount\": followed_profile.get(\"profileAggregates\", {}).get(\"followerCount\") if followed_profile.get(\"profileAggregates\") else None,\n",
    "            \"followingCount\": followed_profile.get(\"profileAggregates\", {}).get(\"followingCount\") if followed_profile.get(\"profileAggregates\") else None,\n",
    "            \"points\": followed_profile.get(\"points\"),\n",
    "            \"credLevel\": followed_profile.get(\"credLevel\"),\n",
    "            \"badge\": followed_profile.get(\"badge\"),\n",
    "            \"phaverFrens\": followed_profile.get(\"phaverFrens\"),\n",
    "            \"verification\": followed_profile.get(\"verification\"),\n",
    "            \"verified\": followed_profile.get(\"verified\"),\n",
    "            \"isUserFollowing\": followed_profile.get(\"isUserFollowing\"),\n",
    "            \"lensProfile.lensHandle\": followed_profile.get(\"lensProfile\", {}).get(\"lensHandle\") if followed_profile.get(\"lensProfile\") else None,\n",
    "            \"lensProfile.isUserFollowing\": followed_profile.get(\"lensProfile\", {}).get(\"isUserFollowing\") if followed_profile.get(\"lensProfile\") else None,\n",
    "            \"farcasterProfile.name\": followed_profile.get(\"farcasterProfile\", {}).get(\"name\") if followed_profile.get(\"farcasterProfile\") else None,\n",
    "            \"farcasterProfile.isUserFollowing\": followed_profile.get(\"farcasterProfile\", {}).get(\"isUserFollowing\") if followed_profile.get(\"farcasterProfile\") else None\n",
    "        }\n",
    "\n",
    "        # Append flattened profile to the list\n",
    "        flattened_data.append(flattened_profile)\n",
    "\n",
    "    return pd.DataFrame(flattened_data)\n",
    "\n",
    "def request_profile(profile_id, access_token):\n",
    "    \"\"\"Fetch the profile data from the API\"\"\"\n",
    "\n",
    "    data = phaver_graphql_api_request(\n",
    "        query = FRAGMENTS + PROFILE_QUERY, \n",
    "        variables = {\n",
    "            \"profileId\": profile_id\n",
    "        }, \n",
    "        access_token = access_token\n",
    "    )\n",
    "\n",
    "    profile = data['data']['profile']\n",
    "    return profile\n",
    "\n",
    "def request_quota(account_id, access_token):\n",
    "    \"\"\"Fetch the quota data from the API\"\"\"\n",
    "\n",
    "    data = phaver_graphql_api_request(\n",
    "        query = FRAGMENTS + QUOTA_QUERY, \n",
    "        variables = {\n",
    "            \"accountId\": account_id\n",
    "        }, \n",
    "        access_token = access_token\n",
    "    )\n",
    "\n",
    "    quota = data['data']['quota']\n",
    "    return quota\n",
    "\n",
    "def unfollow_user(profile_id, network, access_token):\n",
    "    if network not in ['phaver', 'lens', 'farcaster', 'all']:\n",
    "        raise ValueError(\"Invalid network. Must be either 'phaver', 'lens', 'farcaster', or 'all'\")\n",
    "    if network == 'all':\n",
    "        networks = ['phaver', 'lens', 'farcaster']\n",
    "    else:\n",
    "        networks = [network]\n",
    "\n",
    "    profile = request_profile(profile_id, access_token)\n",
    "\n",
    "    if profile is None:\n",
    "        raise ValueError(\"Profile not found\")\n",
    "    \n",
    "    # check if the user is not already unfollowing the profile on Phaver\n",
    "    if 'phaver' in networks and not profile.get('isUserFollowing', False):\n",
    "        networks.remove('phaver')\n",
    "\n",
    "    # check if the profile has a Lens account, and if the user is not already unfollowing the profile on Lens\n",
    "    if 'lens' in networks and (not profile.get('lensProfile') or not profile['lensProfile'].get('isUserFollowing', False)):\n",
    "        networks.remove('lens')\n",
    "\n",
    "    # check if the profile has a Farcaster account, and if the user is not already unfollowing the profile on Farcaster\n",
    "    if 'farcaster' in networks and (not profile.get('farcasterProfile') or not profile['farcasterProfile'].get('isUserFollowing', False)):\n",
    "        networks.remove('farcaster')\n",
    "\n",
    "    if len(networks) == 0:\n",
    "        return True\n",
    "\n",
    "    for network in networks:\n",
    "        data = phaver_graphql_api_request(\n",
    "            query = FRAGMENTS + SET_FOLLOW_MUTATION, \n",
    "            variables = {\n",
    "                \"follow\": False,\n",
    "                \"profileId\": profile_id,\n",
    "                \"followType\": network\n",
    "            }, \n",
    "            access_token = access_token\n",
    "        )\n",
    "\n",
    "        if data['data']['setFollow']['status'] != 'ok':\n",
    "            raise Exception(f\"Failed to unfollow user on {network}\")\n",
    "    \n",
    "    #Check that the profile is not being followed on any network\n",
    "    profile = request_profile(profile_id, access_token)\n",
    "\n",
    "    if profile.get('isUserFollowing', True):\n",
    "        raise Exception(\"Failed to unfollow user on Phaver. Unkown error.\\nprofile: \" + json.dumps(profile, indent=4))\n",
    "    if profile.get('lensProfile') and profile['lensProfile'].get('isUserFollowing', True):\n",
    "        if not profile['lensProfile'].get('isFollowPending', False): # Lens takes some time to update the isUserFollowing field, so we need to check if the follow is pending. If it is, we can assume the unfollow was successful.\n",
    "            quota = request_quota(PHAVER_PROFILE_ID, access_token)\n",
    "            limit = min(quota['lensApiOnchain']['dailyAvailable'], quota['lensApiOnchain']['hourlyAvailable'])\n",
    "            if limit <= 0:\n",
    "                raise Exception(\"Failed to unfollow user on Lens. Onchain Lens API limit reached.\\nprofile: \" + json.dumps(profile, indent=4))\n",
    "            else:\n",
    "                raise Exception(\"Failed to unfollow user on Lens. Unkown error.\\nprofile: \" + json.dumps(profile, indent=4))\n",
    "    if profile.get('farcasterProfile') and profile['farcasterProfile'].get('isUserFollowing', True):\n",
    "        raise Exception(\"Failed to unfollow user on Farcaster. Unkown error.\\nprofile: \" + json.dumps(profile, indent=4))\n",
    "        \n",
    "    return True\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Request Followings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetch all followings for the given profile ID\n",
    "followings = get_all_followings(PHAVER_PROFILE_ID, LIMIT_PER_REQUEST, MAX_FOLLOWINGS_REQUESTED, access_token)\n",
    "\n",
    "# Get the points for each following\n",
    "# followings = get_all_points(followings, access_token)\n",
    "\n",
    "# Save the followings to followings.json\n",
    "save_to_json(followings, 'data/followings.json')\n",
    "\n",
    "print(f\"Successfully saved {len(followings)} followings to 'data/followings.json'.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert JSON to DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flatten the data\n",
    "followings_df = flatten_followings(followings)\n",
    "\n",
    "# Add the current datetime to the DataFrame\n",
    "followings_df['updatedAt'] = pd.Timestamp.now(tz='UTC')\n",
    "\n",
    "# Add a tempo column to mark unfollowed users\n",
    "followings_df['tempo_unfollowed'] = False\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "followings_df.to_csv('data/followings.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Saved Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "followings_df = pd.read_csv('data/followings.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unfollow Profiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter Profiles to Unfollow\n",
    "profiles_to_unfollow_df = followings_df[\n",
    "    (followings_df['followerCount'] < 2000) & \n",
    "    (followings_df['credLevel'] < 2) &\n",
    "    (followings_df['badge'].isnull()) &\n",
    "    (followings_df['verification'].isnull()) &\n",
    "    # (followings_df['lensProfile.isUserFollowing'] != True) &\n",
    "    (followings_df['tempo_unfollowed'] == False) \n",
    "]\n",
    "print(f\"Found {len(profiles_to_unfollow_df)} profiles to unfollow.\")\n",
    "profiles_to_unfollow_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    # Unfollow Profiles\n",
    "    for index, following in profiles_to_unfollow_df.iterrows():\n",
    "        unfollowed = unfollow_user(following['id'], 'all', access_token)\n",
    "        if unfollowed:\n",
    "            print(f\"Unfollowed {following['username']}\")\n",
    "            followings_df.loc[index, 'tempo_unfollowed'] = True\n",
    "except Exception as e:\n",
    "    # Save modified following list\n",
    "    followings_df.to_csv('data/followings.csv', index=False)\n",
    "    raise e\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
