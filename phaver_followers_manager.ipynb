{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "import pandas as pd\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Constants & Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "PHAVER_GRAPHQL_ENDPOINT = os.getenv(\"PHAVER_GRAPHQL_ENDPOINT\")\n",
    "PHAVER_PROFILE_ID = os.getenv(\"PHAVER_PROFILE_ID\")\n",
    "\n",
    "FIREBASE_TOKEN_URL = os.getenv(\"FIREBASE_API_URL\") + os.getenv(\"FIREBASE_API_KEY\")\n",
    "FIREBASE_REFRESH_TOKEN = os.getenv(\"FIREBASE_REFRESH_TOKEN\")\n",
    "\n",
    "LIMIT_PER_REQUEST = 100\n",
    "MAX_FOLLOWINGS_REQUESTED = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utility function to load a GraphQL query or fragment from a file\n",
    "def load_graphql_file(file_path):\n",
    "    with open(file_path, 'r') as file:\n",
    "        return file.read()\n",
    "    \n",
    "# Load fragments and query from their respective files\n",
    "FRAGMENTS = load_graphql_file('graphql/fragments/Fragments.gql')\n",
    "FOLLOWINGS_QUERY = load_graphql_file('graphql/queries/FollowingsQuery.gql')\n",
    "FOLLOWERS_QUERY = load_graphql_file('graphql/queries/FollowersQuery.gql')\n",
    "POINTS_QUERY = load_graphql_file('graphql/queries/PointsQuery.gql')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def request_access_token():\n",
    "    payload = {\n",
    "        \"grantType\": \"refresh_token\",\n",
    "        \"refreshToken\": FIREBASE_REFRESH_TOKEN\n",
    "    }\n",
    "\n",
    "    response = requests.post(FIREBASE_TOKEN_URL, json=payload)\n",
    "    response.raise_for_status()\n",
    "    access_data = response.json()\n",
    "    return access_data['access_token']\n",
    "\n",
    "\n",
    "def request_followings(profile_id, limit_per_request, offset, access_token):\n",
    "    \"\"\"Fetch a batch of followings from the API\"\"\"\n",
    "\n",
    "    headers = {\n",
    "        \"Authorization\": \"Bearer \" + access_token,\n",
    "        \"Content-Type\": \"application/json\"\n",
    "    }\n",
    "    \n",
    "    payload = {\n",
    "        \"query\": FRAGMENTS + FOLLOWINGS_QUERY,\n",
    "        \"variables\": {\n",
    "            \"profileId\": profile_id,\n",
    "            \"limit\": limit_per_request,\n",
    "            \"offset\": offset\n",
    "        }\n",
    "    }\n",
    "    response = requests.post(\n",
    "        PHAVER_GRAPHQL_ENDPOINT, \n",
    "        headers=headers, \n",
    "        json=payload\n",
    "    )\n",
    "    \n",
    "    # Raise an exception for HTTP errors\n",
    "    response.raise_for_status()\n",
    "    \n",
    "    # Parse the JSON response\n",
    "    data = response.json()\n",
    "\n",
    "    # Check if the response contains any errors\n",
    "    if 'errors' in data:\n",
    "        raise Exception(data['errors'])\n",
    "    \n",
    "    # get the followings from the response\n",
    "    followings = data['data']['followings']\n",
    "    \n",
    "    return followings\n",
    "\n",
    "def request_points(profile_id, access_token):\n",
    "    \"\"\"Fetch the points for a profile from the API\"\"\"\n",
    "\n",
    "    headers = {\n",
    "        \"Authorization\": \"Bearer \" + access_token,\n",
    "        \"Content-Type\": \"application/json\"\n",
    "    }\n",
    "    \n",
    "    payload = {\n",
    "        \"query\": FRAGMENTS + POINTS_QUERY,\n",
    "        \"variables\": {\n",
    "            \"profileId\": profile_id\n",
    "        }\n",
    "    }\n",
    "    response = requests.post(\n",
    "        PHAVER_GRAPHQL_ENDPOINT, \n",
    "        headers=headers, \n",
    "        json=payload\n",
    "    )\n",
    "    \n",
    "    # Raise an exception for HTTP errors\n",
    "    response.raise_for_status()\n",
    "    \n",
    "    # Parse the JSON response\n",
    "    data = response.json()\n",
    "\n",
    "    # Check if the response contains any errors\n",
    "    if 'errors' in data:\n",
    "        raise Exception(data['errors'])\n",
    "    \n",
    "    # get the points from the response\n",
    "    points = data['data']['phaverPoints']['phaverPointsCurrent']\n",
    "    \n",
    "    return points\n",
    "\n",
    "\n",
    "def save_to_json(data, filename):\n",
    "    \"\"\"Save the data to a JSON file\"\"\"\n",
    "    # create the folder if it doesn't exist\n",
    "    folder = os.path.dirname(filename)\n",
    "    os.makedirs(folder, exist_ok=True)\n",
    "    with open(filename, 'w') as f:\n",
    "        json.dump(data, f, indent=4)\n",
    "\n",
    "def get_all_points(followings, access_token):\n",
    "    \"\"\"Fetch all points by iterating over paginated results\"\"\"\n",
    "    for following in followings:\n",
    "        profile_id = following['followedProfile']['id']\n",
    "        points = request_points(profile_id, access_token)\n",
    "        following['followedProfile']['points'] = points\n",
    "    return followings\n",
    "\n",
    "\n",
    "def get_all_followings(profile_id, limit_per_request, max_followings_requested, access_token):\n",
    "    \"\"\"Fetch all followings by iterating over paginated results\"\"\"\n",
    "    all_followings = []\n",
    "    offset = 0\n",
    "    \n",
    "    while len(all_followings) < max_followings_requested:\n",
    "        followings = request_followings(profile_id, limit_per_request, offset, access_token)\n",
    "        \n",
    "        # If no more followings, break the loop\n",
    "        if not followings:\n",
    "            break\n",
    "        \n",
    "        # Append the fetched followings to the list\n",
    "        all_followings.extend(followings)\n",
    "        \n",
    "        # Increment the offset by the limit for pagination\n",
    "        offset += limit_per_request\n",
    "        \n",
    "    return all_followings\n",
    "\n",
    "# Function to flatten the JSON data\n",
    "def flatten_followings(followings):\n",
    "    \"\"\"Flatten the followings JSON data into Pandas DataFrame\"\"\"\n",
    "\n",
    "    flattened_data = []\n",
    "\n",
    "    for item in followings:\n",
    "        followed_profile = item['followedProfile']\n",
    "       \n",
    "        # Flatten the nested fields\n",
    "        flattened_profile = {\n",
    "            \"id\": followed_profile.get(\"id\"),\n",
    "            \"username\": followed_profile.get(\"username\"),\n",
    "            \"profileCreatedAt\": followed_profile.get(\"createdAt\"),\n",
    "            \"followingDate\": item.get(\"createdAt\"),\n",
    "            \"followerCount\": followed_profile.get(\"profileAggregates\", {}).get(\"followerCount\") if followed_profile.get(\"profileAggregates\") else None,\n",
    "            \"followingCount\": followed_profile.get(\"profileAggregates\", {}).get(\"followingCount\") if followed_profile.get(\"profileAggregates\") else None,\n",
    "            \"points\": followed_profile.get(\"points\"),\n",
    "            \"credLevel\": followed_profile.get(\"credLevel\"),\n",
    "            \"badge\": followed_profile.get(\"badge\"),\n",
    "            \"phaverFrens\": followed_profile.get(\"phaverFrens\"),\n",
    "            \"verification\": followed_profile.get(\"verification\"),\n",
    "            \"verified\": followed_profile.get(\"verified\"),\n",
    "            \"isUserFollowing\": followed_profile.get(\"isUserFollowing\"),\n",
    "            \"lensProfile.lensHandle\": followed_profile.get(\"lensProfile\", {}).get(\"lensHandle\") if followed_profile.get(\"lensProfile\") else None,\n",
    "            \"lensProfile.isUserFollowing\": followed_profile.get(\"lensProfile\", {}).get(\"isUserFollowing\") if followed_profile.get(\"lensProfile\") else None,\n",
    "            \"farcasterProfile.name\": followed_profile.get(\"farcasterProfile\", {}).get(\"name\") if followed_profile.get(\"farcasterProfile\") else None,\n",
    "            \"farcasterProfile.isUserFollowing\": followed_profile.get(\"farcasterProfile\", {}).get(\"isUserFollowing\") if followed_profile.get(\"farcasterProfile\") else None\n",
    "        }\n",
    "\n",
    "        # Append flattened profile to the list\n",
    "        flattened_data.append(flattened_profile)\n",
    "\n",
    "    return pd.DataFrame(flattened_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Request Token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "access_token = request_access_token()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Request Followings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully saved 100 followings to 'data/followings.json'.\n"
     ]
    }
   ],
   "source": [
    "# Fetch all followings for the given profile ID\n",
    "followings = get_all_followings(PHAVER_PROFILE_ID, LIMIT_PER_REQUEST, MAX_FOLLOWINGS_REQUESTED, access_token)\n",
    "\n",
    "# Get the points for each following\n",
    "# followings = get_all_points(followings, access_token)\n",
    "\n",
    "# Save the followings to followings.json\n",
    "save_to_json(followings, 'data/followings.json')\n",
    "\n",
    "print(f\"Successfully saved {len(followings)} followings to 'data/followings.json'.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert JSON to DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flatten the data\n",
    "followings_df = flatten_followings(followings)\n",
    "\n",
    "# Add the current datetime to the DataFrame\n",
    "followings_df['updatedAt'] = pd.Timestamp.now(tz='UTC')\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "# followings_df.to_csv('data/followings.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Filter Out Profiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_out_followings_df = followings_df[\n",
    "    (followings_df['followerCount'] < 1000) & \n",
    "    (followings_df['credLevel'] < 2) &\n",
    "    (followings_df['badge'].isnull()) &\n",
    "    (followings_df['verification'].isnull())\n",
    "]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
